<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es" >

<head>
    <meta charset="utf-8" />
    <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />        <title>1. Introducción. Conceptos iniciales</title>
    <style>
        code{white-space: pre-wrap;}
        span.smallcaps{font-variant: small-caps;}
        div.columns{display: flex; gap: min(4vw, 1.5em);}
        div.column{flex: auto; overflow-x: auto;}
        div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
        /* The extra [class] is a hack that increases specificity enough to
           override a similar rule in reveal.js */
        ul.task-list[class]{list-style: none;}
        ul.task-list li input[type="checkbox"] {
          font-size: inherit;
          width: 0.8em;
          margin: 0 0.8em 0.2em -1.6em;
          vertical-align: middle;
        }
        .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    </style>
        <link rel="stylesheet" href="aqua.css" />  
    <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
    <![endif]-->
      
</head>

<body>
    <div id="content">
                 <header id="title-block-header">
            <h1 class="title">1. Introducción. Conceptos iniciales</h1>
            <!---->
            <!--  -->
                    </header>
                 <nav id="TOC" role="doc-toc">
            <div class="navContainer">
                 <ul>
<li><a href="#introducción" id="toc-introducción"><span
class="toc-section-number">1</span> Introducción</a></li>
<li><a href="#qué-es-y-qué-no-es-la-inteligencia-artificial"
id="toc-qué-es-y-qué-no-es-la-inteligencia-artificial"><span
class="toc-section-number">2</span> Qué es y qué no es la inteligencia
artificial?</a>
<ul>
<li><a href="#modelos-de-lenguaje-a-gran-escala"
id="toc-modelos-de-lenguaje-a-gran-escala"><span
class="toc-section-number">2.1</span> Modelos de Lenguaje a Gran
Escala</a></li>
<li><a href="#modelos-de-difusión" id="toc-modelos-de-difusión"><span
class="toc-section-number">2.2</span> Modelos de Difusión</a></li>
<li><a href="#modelos-de-difusión-1"
id="toc-modelos-de-difusión-1"><span
class="toc-section-number">2.3</span> Modelos de difusión</a></li>
<li><a href="#ejemplos-de-uso-para-empezar-a-experimentar"
id="toc-ejemplos-de-uso-para-empezar-a-experimentar"><span
class="toc-section-number">2.4</span> Ejemplos de Uso para Empezar a
Experimentar</a>
<ul>
<li><a href="#teachable-machine-de-google"
id="toc-teachable-machine-de-google"><span
class="toc-section-number">2.4.1</span> Teachable Machine de
Google</a></li>
<li><a href="#autodraw" id="toc-autodraw"><span
class="toc-section-number">2.4.2</span> Autodraw</a></li>
<li><a href="#quickdraw" id="toc-quickdraw"><span
class="toc-section-number">2.4.3</span> Quickdraw</a></li>
<li><a href="#labs-google" id="toc-labs-google"><span
class="toc-section-number">2.4.4</span> Labs Google</a></li>
</ul></li>
</ul></li>
</ul>
            </div>
        </nav>
                <main>
            <!-- \awesomebox[violet]{2pt}{\faRocket}{violet}{Lorem ipsum…} -->
            <!-- \awesomebox[violet]{2pt}{\faRobot}{violet}{Lorem ipsum…} -->
            <!-- IMATGE ![Pregunta inicial](./img/proxi/5b.png) -->
            <!-- \textbf{greatest} -->
            <p><img src="img/cc.png" height="50" /></p>
            <p>Este documento está sujeto a una licencia creative
            commons que permite su difusión y uso comercial reconociendo
            siempre la autoría de su creador. Este documento se
            encuentra para ser modificado en el siguiente repositorio de
            github: <!-- CANVIAR L'ENLLAÇ --> <a
            href="https://github.com/arvicenteboix/AICurs25">https://github.com/arvicenteboix/AICurs25</a>
            </p>
            <h1 data-number="1" id="introducción"><span
            class="header-section-number">1</span> Introducción</h1>
            <p>Seguramente muchos de vosotros ya habéis oído hablar de
            la inteligencia artificial y de todo lo que puede hacer.
            Algunos ya habéis empezado a utilizarla en vuestro día a día
            y sabéis distinguir algunos conceptos sobre qué es la IA. En
            este curso trataremos de haceros una introducción sobre las
            diferentes herramientas que existen y cómo sacarles
            provecho.</p>
            <p>Se trata de un curso de iniciación y es posible que os
            sintáis abrumados por toda la información que veis, pero no
            se os pide que profundicéis en muchas de las utilidades que
            os presentaremos. El curso será breve pero intenso, y
            trataremos de ayudaros con todas las dudas que se planteen.
            Todo el texto escrito está redactado sin utilizar
            inteligencia artificial, aunque algunas imágenes son la
            excepción. En muchos casos os proporcionaremos un prompt<a
            href="#fn1" class="footnote-ref" id="fnref1"
            role="doc-noteref"><sup>1</sup></a> y la respuesta que
            obtendréis. Trataremos de limitar la extensión a lo que
            realmente necesitéis. Os lo presentaremos con el siguiente
            icono.</p>
            <div class="note">
            <p>Se trata de una respuesta de inteligencia artificial.
            Debido a la complejidad del trabajo, no sería posible
            escribir un modelo desde cero sin mucho tiempo y
            esfuerzo.</p>
            </div>
            <div class="warning">
            <p>Se recomienda crear un cuenta de correo electrónico
            específica para experimentar con estas herramientas y
            servicios. Esto permitirá mantener tu cuenta principal libre
            de correos electrónicos no deseados y proteger tu
            privacidad. Puedes utilizar proveedores de correo
            electrónico como Gmail, Outlook o cualquier otro servicio
            gratuito para este propósito.</p>
            </div>
            <h1 data-number="2"
            id="qué-es-y-qué-no-es-la-inteligencia-artificial"><span
            class="header-section-number">2</span> Qué es y qué no es la
            inteligencia artificial?</h1>
            <p>Podemos pensar que todo lo que hacemos en el ordenador
            tiene que ver con la inteligencia artificial, pero
            obviamente no es así. Los ordenadores utilizan algoritmos
            con lenguajes de programación para poder automatizar tareas
            o realizar programas. Los algoritmos son una serie de pasos
            que se siguen para realizar una tarea. Aquí tenéis un
            ejemplo de diagrama de flujo sencillo que muestra un
            proceso::</p>
            <!-- DIAGRAMA DE FLUJO -->
            <figure>
            <img src="img/1.png" height="300"
            alt="Diagrama de flujo. Origen: Wikipedia" />
            <figcaption aria-hidden="true">Diagrama de flujo. Origen:
            Wikipedia</figcaption>
            </figure>
            <p>Estas funciones llevan una lógica detrás, en cambio las
            IA utilizan un modo de programación diferente que mezcla
            muchas más posibilidades para dar una respuesta más creativa
            basándose en entradas más complejas, a esto lo llamamos
            redes neuronales. Aquí tenemos un ejemplo de red
            neuronal</p>
            <figure>
            <img src="img/2.png" height="300"
            alt="Red neuronal. Origen: Wikipedia" />
            <figcaption aria-hidden="true">Red neuronal. Origen:
            Wikipedia</figcaption>
            </figure>
            <p>Existe una clase de arquitectura llamada <strong>modelos
            de transformadores</strong> que se basan en redes
            neuronales. Estos modelos son capaces de aprender patrones
            en los datos y generar respuestas más complejas. Aunque no
            profundizaremos en cómo funcionan, es importante que sepáis
            que existen.</p>
            <div class="note">
            <p>La Inteligencia Artificial (IA) es un campo amplio que
            incluye diferentes técnicas y algoritmos para crear sistemas
            que puedan simular la inteligencia humana. Las redes
            neuronales son una de las técnicas de IA que imitan el
            funcionamiento del cerebro humano para resolver
            problemas</p>
            </div>
            <p>Dentro del mismo campo de la inteligencia artificial nos
            podemos encontrar diferentes categorías que iremos viendo a
            lo largo de los próximos años.</p>
            <table>
            <colgroup>
            <col style="width: 33%" />
            <col style="width: 33%" />
            <col style="width: 33%" />
            </colgroup>
            <thead>
            <tr>
            <th>Tipo de IA</th>
            <th>Descripción</th>
            <th>Ejemplos</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>Inteligencia Artificial Estrecha
            (IAE)</strong></td>
            <td>La IAE está programada para realizar una sola tarea, ya
            sea verificar el clima, jugar al ajedrez o analizar datos
            para escribir informes periodísticos. Los sistemas IAE
            pueden atender una tarea en tiempo real, pero extraen
            información de un conjunto de datos específico. No funcionan
            fuera de la única tarea para la cual están diseñados.</td>
            <td>Asistentes virtuales como Siri o Alexa, sistemas de
            reconocimiento facial, coches autónomos.</td>
            </tr>
            <tr>
            <td><strong>Inteligencia Artificial General
            (IAG)</strong></td>
            <td>La IAG es una forma de IA que puede aprender y entender
            cualquier tarea intelectual que un ser humano pueda
            realizar. La IAG es capaz de razonar, planificar, aprender,
            comprender lenguajes naturales e integrar diversos
            conocimientos para resolver problemas complejos.</td>
            <td>Aún en desarrollo, objeto de investigación
            académica.</td>
            </tr>
            <tr>
            <td><strong>Inteligencia Artificial Superintelectual
            (IAS)</strong></td>
            <td>La IAS se refiere a una IA que sobrepasa la inteligencia
            y capacidades cognitivas de todos los humanos en
            prácticamente todos los campos, incluyendo creatividad
            científica, sabiduría general y habilidades sociales.</td>
            <td>Teóricamente posible, pero aún no existe; concepto
            popularizado por científicos e futuristas como Nick
            Bostrom<a href="#fn2" class="footnote-ref" id="fnref2"
            role="doc-noteref"><sup>2</sup></a>.</td>
            </tr>
            </tbody>
            </table>
            <h2 data-number="2.1"
            id="modelos-de-lenguaje-a-gran-escala"><span
            class="header-section-number">2.1</span> Modelos de Lenguaje
            a Gran Escala</h2>
            <p>Los Modelos de Lenguaje a Gran Escala (LLM, por las
            siglas en inglés, Large Language Models) son modelos de
            inteligencia artificial que han sido entrenados con enormes
            cantidades de datos textuales para aprender patrones,
            estructuras y representaciones del lenguaje natural. Estos
            modelos son capaces de realizar tareas relacionadas con el
            procesamiento del lenguaje, como entender el significado de
            frases, generar texto coherente y responder preguntas.</p>
            <p>Algunos de los modelos de lenguaje a gran escala más
            conocidos son:</p>
            <ol type="1">
            <li><p><strong>RoBERTa (Robustly Optimized BERT
            Approach)</strong>: Una variante de BERT desarrollada por
            Facebook AI, que está optimizada para obtener mejor
            rendimiento en diversas tareas del lenguaje
            natural.</p></li>
            <li><p><strong>XLNet</strong>: Creado por Google Brain, este
            modelo combina los mejores elementos de BERT y autoencoders
            secuenciales para mejorar la comprensión de contextos largos
            en tareas de lenguaje natural.</p></li>
            <li><p><strong>ALBERT (A Lite BERT)</strong>: Desarrollado
            por Google Research, es una versión más ligera de BERT que
            utiliza menos recursos computacionales manteniendo el
            rendimiento.</p></li>
            <li><p><strong>DistilBERT</strong>: Creado por Hugging Face,
            este modelo es una versión más pequeña y eficiente de BERT
            que conserva el 97% del rendimiento con solo el 60% del peso
            del modelo original.</p></li>
            <li><p><strong>Electra</strong>: También desarrollado por
            Google, este modelo utiliza una nueva técnica de
            entrenamiento para hacer modelos más eficientes y con un
            rendimiento mejor en tareas de lenguaje natural.</p></li>
            <li><p><strong>GPT-Neo</strong>: Un modelo de código abierto
            desarrollado por EleutherAI como alternativa a GPT-3,
            disponible para la comunidad de investigación y
            desarrollo.</p></li>
            <li><p><strong>Megatron-LM</strong>: Desarrollado por
            NVIDIA, es un modelo de gran escala entrenado con una
            versión mejorada de transformers, optimizado para GPU de
            NVIDIA.</p></li>
            <li><p><strong>Turing-NLG</strong>: Desarrollado por
            Microsoft, este modelo es uno de los modelos más poderosos
            de lenguaje natural de gran escala creado para tareas
            complejas de IA.</p></li>
            <li><p><strong>GPT-3 y 4</strong> (Generative Pre-trained
            Transformer) de OpenAI</p></li>
            <li><p><strong>BERT</strong> (Bidirectional Encoder
            Representations from Transformers) de Google</p></li>
            <li><p><strong>T5</strong> (Text-to-Text Transfer
            Transformer) de Google.</p></li>
            <li><p><strong>Llama</strong> de Meta: Un modelo de lenguaje
            a gran escala desarrollado por Meta (anteriormente Facebook)
            que se centra en la eficiencia y la sostenibilidad.</p></li>
            </ol>
            <div class="note">
            <p>No es importante que conozcáis estos Nombres pero cuando
            usemos diferentes modelos en el próximo módulo veremos como
            usarlos.</p>
            </div>
            <p>Estos son solo algunos de los muchas versiones de LLM que
            están ayudando a avanzar la investigación y aplicaciones en
            el campo de la inteligencia artificial.</p>
            <p>Algunas aplicaciones destacadas de los LLM son:</p>
            <ol type="1">
            <li><p><strong>Generación de Texto Creativo</strong>: LLM
            como GPT-3 pueden usarse para generar contenido textual
            creativo, desde poesía hasta narrativa.</p></li>
            <li><p><strong>Asistentes Virtuales Avanzados</strong>: LLM
            se integran en asistentes virtuales para mejorar la
            capacidad de comprensión y generación de respuestas en
            lenguaje natural.</p></li>
            <li><p><strong>Traducción Automática Mejorada</strong>:
            Modelos como T5 han demostrado mejoras significativas en
            tareas de traducción automática.</p></li>
            <li><p><strong>Generación de Resúmenes Automáticos</strong>:
            LLM son empleados para resumir automáticamente textos
            largos, extrayendo información clave.</p></li>
            <li><p><strong>Preguntas y Respuestas</strong>: Modelos como
            BERT se utilizan en sistemas de preguntas y respuestas para
            entender y responder consultas en lenguaje natural.</p></li>
            <li><p><strong>Análisis de Sentimiento Avanzado</strong>:
            LLM pueden mejorar la capacidad de analizar el sentimiento
            en grandes cantidades de texto, beneficiando aplicaciones en
            redes sociales y comentarios en línea.</p></li>
            <li><p><strong>Autocompletado de Texto Mejorado</strong>:
            Herramientas de autocompletado, como las utilizadas en
            correos electrónicos o búsquedas en la web, se benefician de
            la capacidad predictiva de los LLM.</p></li>
            <li><p><strong>Creación de Contenido Multimedio</strong>:
            LLM pueden combinarse con otros modelos de inteligencia
            artificial para crear contenido multimedió, como imágenes,
            vídeos o audio, a partir de texto.</p></li>
            <li><p><strong>Creación de Contenido para Redes
            Sociales</strong>: Los LLM se utilizan para generar
            contenido relevante y atractivo en plataformas de redes
            sociales.</p></li>
            <li><p><strong>Reconocimiento de Entidades
            Mejorado</strong>: Modelos como GPT-3 pueden ayudar en la
            identificación y clasificación precisa de entidades en
            textos.</p></li>
            <li><p><strong>Personalización de Recomendaciones</strong>:
            Los LLM contribuyen a mejorar la personalización en sistemas
            de recomendación en áreas como streaming y comercio
            electrónico.</p></li>
            </ol>
            <p>Estas aplicaciones resaltan cómo los LLM están
            transformando la forma en que las máquinas interactúan con
            el lenguaje humano, abriendo nuevas posibilidades en
            diversas áreas.</p>
            <h2 data-number="2.2" id="modelos-de-difusión"><span
            class="header-section-number">2.2</span> Modelos de
            Difusión</h2>
            <p>Los modelos de difusión, como DALL-E, son modelos
            generativos avanzados que utilizan técnicas de difusión para
            generar imágenes. Estos modelos se basan en la difusión
            probabilística, que es un proceso estocástico para generar
            datos complejos paso a paso. En lugar de generar
            directamente píxeles de una imagen, los modelos de difusión
            generan una imagen al “difundiendo” gradualmente información
            a través de múltiples pasos, lo que permite capturar
            patrones complejos y estructuras en los datos.</p>
            <h2 data-number="2.3" id="modelos-de-difusión-1"><span
            class="header-section-number">2.3</span> Modelos de
            difusión</h2>
            <p>Los modelos de difusión, como DALL-E, son modelos
            generativos avanzados que utilizan técnicas de difusión para
            generar imágenes. Estos modelos se basan en la difusión
            probabilística, que es un proceso estocástico para generar
            datos complejos paso a paso. En lugar de generar
            directamente píxeles de una imagen, los modelos de difusión
            generan una imagen “difundiendo” gradualmente información a
            través de múltiples pasos, lo cual permite capturar patrones
            complejos y estructuras en los datos.</p>
            <p>Ejemplos de modelos de difusión incluyen:</p>
            <table>
            <colgroup>
            <col style="width: 50%" />
            <col style="width: 50%" />
            </colgroup>
            <thead>
            <tr>
            <th>Modelo de Difusión</th>
            <th>Descripción</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>DALL-E</strong></td>
            <td>Desarrollado por OpenAI, DALL-E es conocido por generar
            imágenes creativas a partir de descripciones textuales.
            Puede crear imágenes realistas y únicas a partir de
            conceptos específicos.</td>
            </tr>
            <tr>
            <td><strong>MidJourney</strong></td>
            <td>Otro modelo de difusión que se centra en la generación
            de imágenes a través de procesos de difusión probabilística.
            Puede utilizarse para crear imágenes realistas y
            detalladas.</td>
            </tr>
            <tr>
            <td><strong>Stable Diffusion</strong></td>
            <td>Un enfoque de difusión que busca lograr una difusión más
            estable y eficiente en términos de entrenamiento y
            generación de imágenes.</td>
            </tr>
            <tr>
            <td><strong>Imagen</strong></td>
            <td>Desarrollado por Google Research, es un modelo de
            difusión que genera imágenes a partir de descripciones
            textuales con una calidad de alta fidelidad. Utiliza
            técnicas de difusión avanzadas para mejorar la nitidez y el
            detalle de las imágenes generadas.</td>
            </tr>
            <tr>
            <td><strong>VQ-VAE-2</strong></td>
            <td>Un modelo de difusión basado en VQ-VAE (Vector Quantized
            Variational Autoencoder), utilizado para la generación de
            datos visuales de alta calidad. Es conocido por su capacidad
            de generar imágenes con detalle fino y colores vivos.</td>
            </tr>
            <tr>
            <td><strong>BigGAN</strong></td>
            <td>Desarrollado por Google, BigGAN es un modelo de red
            adversaria generativa que utiliza técnicas de difusión para
            generar imágenes de alta calidad con resoluciones elevadas.
            Es utilizado para aplicaciones donde se requieren imágenes
            realistas y detalladas.</td>
            </tr>
            <tr>
            <td><strong>DDPM</strong></td>
            <td>Denoising Diffusion Probabilistic Models (DDPM) son
            modelos de difusión probabilística que eliminan el ruido de
            manera progresiva para generar imágenes nítidas. Se utilizan
            en diversas aplicaciones de generación de imágenes.</td>
            </tr>
            </tbody>
            </table>
            <p>Estos modelos de difusión tienen aplicaciones en varias
            áreas, incluyendo:</p>
            <ol type="1">
            <li><p><strong>Generación de Imágenes Artísticas y
            Creativas</strong>: Los modelos de difusión como DALL-E se
            utilizan para generar imágenes artísticas y creativas
            basadas en descripciones textuales.</p></li>
            <li><p><strong>Reconstrucción y Mejora de Imágenes</strong>:
            Pueden aplicarse para reconstruir o mejorar imágenes
            existentes, generando versiones más detalladas o
            modificadas.</p></li>
            <li><p><strong>Generación de Contenido Visual
            Personalizado</strong>: Se pueden emplear en la creación de
            contenido visual personalizado para aplicaciones de diseño
            gráfico, publicidad y marketing.</p></li>
            <li><p><strong>Simulación y Entrenamiento en Realidad
            Virtual</strong>: Estos modelos pueden generar escenarios
            visuales realistas para aplicaciones de realidad virtual,
            simulación y entrenamiento.</p></li>
            <li><p><strong>Síntesis de Datos para la
            Investigación</strong>: En ámbitos como la investigación
            científica y médica, los modelos de difusión pueden
            sintetizar datos visuales para fines
            experimentales.</p></li>
            <li><p><strong>Generación de Contenido para
            Videojuegos</strong>: Pueden utilizarse en la creación de
            mundos y elementos visuales en videojuegos, ofreciendo
            variedad y realismo.</p></li>
            <li><p><strong>Creación de Ilustraciones y Arte
            Digital</strong>: Los artistas digitales pueden emplear
            modelos de difusión para crear ilustraciones y arte digital
            único.</p></li>
            </ol>
            <p>Estas aplicaciones destacan la versatilidad de los
            modelos de difusión en la generación de contenido visual,
            desde la creación de arte hasta la simulación de entornos
            complejos. Su capacidad para manejar datos de manera
            probabilística y generar resultados detallados los hace
            valiosos en diversas disciplinas creativas y
            tecnológicas.</p>
            <h2 data-number="2.4"
            id="ejemplos-de-uso-para-empezar-a-experimentar"><span
            class="header-section-number">2.4</span> Ejemplos de Uso
            para Empezar a Experimentar</h2>
            <h3 data-number="2.4.1"
            id="teachable-machine-de-google"><span
            class="header-section-number">2.4.1</span> Teachable Machine
            de Google</h3>
            <p>Teachable Machine de Google es una plataforma que permite
            a los usuarios crear modelos de aprendizaje automático sin
            necesidad de escribir código. Los usuarios pueden entrenar
            modelos de clasificación de imágenes, sonidos o posiciones
            utilizando una interfaz amigable, facilitando la
            incorporación de inteligencia artificial en proyectos
            creativos.</p>
            <p>Esta herramienta nos permite entrenar a pequeña escala
            nuestro modelo de inteligencia artificial para un propósito,
            por ejemplo el de reconocer objetos, sonidos o posturas.
            Solo necesitamos una webcam para hacerlo. Pueden acceder a
            la plataforma desde aquí:
            [https://teachablemachine.withgoogle.com/]</p>
            <figure>
            <img src="img/24.png" style="width:13cm"
            alt="Teachablemachine" />
            <figcaption aria-hidden="true">Teachablemachine</figcaption>
            </figure>
            <p>Y creamos nuestro primer proyecto</p>
            <figure>
            <img src="img/25.png" style="width:13cm"
            alt="Modelo de imagen" />
            <figcaption aria-hidden="true">Modelo de imagen</figcaption>
            </figure>
            <p>¡Nosotros hemos preparado un modelo para distinguir entre
            un bolígrafo y unas tijeras, subiendo imágenes de cada
            uno!</p>
            <figure>
            <img src="img/26.png" style="width:13cm"
            alt="Modelo de imagen creado" />
            <figcaption aria-hidden="true">Modelo de imagen
            creado</figcaption>
            </figure>
            <p>Este modelo lo podemos exportar y compartir. Obviamente
            el modelo que he creado no es muy interesante, pero puedes
            entrenar mejores modelos con muchas fotos, de objetos
            específicos y crear tu propio reconocedor de objetos. Puedes
            descargar el modelo desde <a
            href="https://teachablemachine.withgoogle.com/models/9OqM8E4An/">aquí</a></p>
            <h3 data-number="2.4.2" id="autodraw"><span
            class="header-section-number">2.4.2</span> Autodraw</h3>
            <p>La función principal de AutoDraw es facilitar la creación
            de dibujos reconocibles incluso para aquellos que no son
            hábiles en el dibujo. La herramienta ofrece una variedad de
            ícones y formas que coinciden con el contenido aproximado
            del dibujo original, permitiendo a los usuarios mejorar y
            refinar sus creaciones de manera intuitiva.</p>
            <p><a
            href="https://www.autodraw.com/">https://www.autodraw.com/</a></p>
            <p>Por ejemplo, si dibujamos un barco lo mejor que
            sabemos</p>
            <figure>
            <img src="img/3.png" style="width:13cm"
            alt="Imagen dibujada por nosotros" />
            <figcaption aria-hidden="true">Imagen dibujada por
            nosotros</figcaption>
            </figure>
            <p>La barra de menú superior de la plataforma cambiará
            intentando adivinar qué hemos dibujado y nos proporcionará
            una imagen un poco mejor dibujada de lo que hemos hecho.</p>
            <figure>
            <img src="img/4.png" style="width:13cm"
            alt="Imagen del menú seleccionada" />
            <figcaption aria-hidden="true">Imagen del menú
            seleccionada</figcaption>
            </figure>
            <h3 data-number="2.4.3" id="quickdraw"><span
            class="header-section-number">2.4.3</span> Quickdraw</h3>
            <p>Quick, Draw! es un juego en línea desarrollado por Google
            que utiliza inteligencia artificial para reconocer y
            clasificar dibujos realizados por los usuarios en un tiempo
            limitado. El funcionamiento básico del juego es el
            siguiente:</p>
            <ol type="1">
            <li><p><strong>Dibujar Rápido</strong>: El jugador recibe
            una palabra sugerida y tiene un tiempo limitado
            (generalmente 20 segundos) para dibujar el objeto o concepto
            asociado en una pantalla digital.</p></li>
            <li><p><strong>Reconocimiento en Tiempo Real</strong>:
            Mientras el jugador dibuja, la inteligencia artificial
            intenta adivinar lo que está representando en tiempo real.
            Utiliza algoritmos de aprendizaje automático y redes
            neuronales para analizar el trazo del dibujo.</p></li>
            <li><p><strong>Retroalimentación Instantánea</strong>: Una
            vez que se completa el tiempo de dibujo, el juego
            proporciona retroalimentación instantánea sobre si la
            inteligencia artificial ha reconocido correctamente el
            dibujo o no. Además, muestra ejemplos de cómo otros usuarios
            han representado la misma palabra.</p></li>
            <li><p><strong>Contribución al Conjunto de Datos de
            Entrenamiento</strong>: Los dibujos realizados por los
            usuarios no solo son parte del juego, sino que también
            contribuyen al conjunto de datos utilizado para entrenar y
            mejorar los algoritmos de reconocimiento de Google.</p></li>
            </ol>
            <p>En resumen, Quick, Draw! a través del entretenimiento de
            un juego en línea recopila nuestros datos para mejorar los
            modelos de inteligencia artificial de reconocimiento de
            patrones.</p>
            <p><a
            href="https://quickdraw.withgoogle.com/">https://quickdraw.withgoogle.com/</a></p>
            <div class="note">
            <p>Se trata de un juego sencillo que nos permitirá
            experimentar con una red neuronal. Esta tratará de adivinar
            qué es lo que estamos dibujando con un tiempo de 20
            segundos.</p>
            </div>
            <figure>
            <img src="img/5.png" style="width:13cm" alt="Juego" />
            <figcaption aria-hidden="true">Juego</figcaption>
            </figure>
            <figure>
            <img src="img/6.png" style="width:13cm"
            alt="Imagen a adivinar" />
            <figcaption aria-hidden="true">Imagen a
            adivinar</figcaption>
            </figure>
            <figure>
            <img src="img/7.png" style="width:13cm"
            alt="Nuestro dibujo" />
            <figcaption aria-hidden="true">Nuestro dibujo</figcaption>
            </figure>
            <p>Así seguirá durante 6 imágenes. Es un buen ejercicio para
            entender cómo funcionan las redes neuronales.</p>
            <figure>
            <img src="img/8.png" style="width:13cm"
            alt="Nos ha acertado los 6" />
            <figcaption aria-hidden="true">Nos ha acertado los
            6</figcaption>
            </figure>
            <h3 data-number="2.4.4" id="labs-google"><span
            class="header-section-number">2.4.4</span> Labs Google</h3>
            <p>Google ofrece <a href="https://labs.google/">Labs
            Google</a>, una serie de laboratorios en línea para
            experimentar con la inteligencia artificial y otras
            tecnologías. Estos laboratorios proporcionan herramientas
            interactivas y guías paso a paso para aprender conceptos
            clave y aplicarlos en proyectos prácticos. Algunos de los
            laboratorios donde se puede practicar son:</p>
            <h4 data-number="2.4.4.1" id="gentype"><span
            class="header-section-number">2.4.4.1</span> Gentype</h4>
            <p>Gentype es un laboratorio interactivo que nos permite
            explorar y experimentar con la generación de textos
            creativos utilizando modelos de lenguaje a gran escala. El
            laboratorio ofrece herramientas para generar textos,
            modificarlos y compartilos con otros usuarios. También
            proporciona información sobre los modelos de lenguaje
            utilizados y cómo funcionan. Puedes acceder a Gentype desde
            <a href="https://labs.google/gentype">aquí</a></p>
            <p>Tendremos que logearnos con una cuenta de google para
            poder acceder a la plataforma. Luego podemos darle una
            descripción del tipo de texto que queremos generar:</p>
            <figure>
            <img src="img/27.png" style="width:13cm"
            alt="Descripción" />
            <figcaption aria-hidden="true">Descripción</figcaption>
            </figure>
            <p>Luego podremos generar un texto con la nueva tipografía y
            descargarlo con una imagen que podré utilizat:</p>
            <figure>
            <img src="img/28.png" style="width:13cm"
            alt="Texto generado" />
            <figcaption aria-hidden="true">Texto generado</figcaption>
            </figure>
            <p>Imagen generada:</p>
            <figure>
            <img src="img/29.png" style="width:13cm"
            alt="Imagen generada" />
            <figcaption aria-hidden="true">Imagen generada</figcaption>
            </figure>
            <h4 data-number="2.4.4.2" id="say-what-you-see"><span
            class="header-section-number">2.4.4.2</span> Say what you
            see</h4>
            <p><em>Say what you see</em> es un laboratorio que prueba tu
            capacidad de describir imágenes con palabras. El laboratorio
            muestra una serie de imágenes y te pide que las describas
            con frases cortas y concisas. Además, puedes comparar tus
            descripciones con las de otros usuarios y ver cómo la
            inteligencia artificial interpreta las imágenes. Puedes
            acceder a <em>Say what you see</em> desde <a
            href="https://artsandculture.google.com/experiment/say-what-you-see/jwG3m7wQShZngw">aquí</a></p>
            <div class="warning">
            <p>Uno de los principales inconvenientes de esta herramienta
            es que está en inglés, pero es importante practicarla ya que
            los prompts para generar imágenes es mejor hacerlos en
            inglés. Esta herramienta nos permitirá mejorar la creación
            de nuestros prompts para generar imágenes ya que nos da
            feedback de qué estamos haciendo bien y qué no.</p>
            </div>
            <p>En este caso hemos probado el nivel 1, donde nos piden
            describir algunas imágenes, luego nos dice un feedback del
            prompt que hemos creado:</p>
            <figure>
            <img src="img/30.png" style="width:13cm"
            alt="Say what you see" />
            <figcaption aria-hidden="true">Say what you see</figcaption>
            </figure>
            <p>Entramos al nivel 1:</p>
            <figure>
            <img src="img/31.png" style="width:13cm" alt="Nivel 1" />
            <figcaption aria-hidden="true">Nivel 1</figcaption>
            </figure>
            <p>Y aquí tenéis dos ejemplos de dos imágenes con sus
            prompts. Fijaros que abajo nos da un feedback del prompt que
            hemos creado:</p>
            <figure>
            <img src="img/32.png" style="width:13cm" alt="Imagen 1" />
            <figcaption aria-hidden="true">Imagen 1</figcaption>
            </figure>
            <figure>
            <img src="img/33.png" style="width:13cm" alt="Imagen 2" />
            <figcaption aria-hidden="true">Imagen 2</figcaption>
            </figure>
            <div class="note">
            <p>En este módulo hemos visto una pequeña introducción a las
            posibilidades que nos ofrece la IA y las tecnologías que se
            están desarrollando en ese sentido. Además, una serie de
            conceptos muy básicos para tener en cuenta, pero… ¿Cuándo
            nos ponemos a hacer prompts? Esto lo veremos en el próximo
            módulo…</p>
            </div>
            <section id="footnotes"
            class="footnotes footnotes-end-of-document"
            role="doc-endnotes">
            <hr />
            <ol>
            <li id="fn1"><p>Prompt es el texto que escribes en la
            plataforma para que interprete lo que realmente necesitas.
            Entraremos en más detalle en la próxima unidad.<a
            href="#fnref1" class="footnote-back"
            role="doc-backlink">↩︎</a></p></li>
            <li
            id="fn2"><p>https://es.wired.com/articulos/nick-bostrom-hizo-al-mundo-temer-por-la-ia-ahora-pregunta-y-si-es-la-solucion-a-todos-nuestros-problemas<a
            href="#fnref2" class="footnote-back"
            role="doc-backlink">↩︎</a></p></li>
            </ol>
            </section>
        </main>
        

        <!--- Modal images -->

        <!-- The Modal -->
        <div id="myModal" class="modal">

            <!-- The Close Button -->
            <!--span class="close">&times;</span-->

            <!-- Modal Content (The Image) -->
            <img class="modal-content" id="img01">

            <!-- Modal Caption (Image Text) -->
            <div id="caption"></div>
        </div>

        <!-- End Modal Images -->

        <script>
            function ModalizeImages() {
                // Script basat en https://www.w3schools.com/howto/howto_css_modal_images.asp
                // PEr ampliar imatges en fer click

                // Get the modal
                var modal = document.getElementById("myModal");

                var modalImg = document.getElementById("img01");
                var captionText = document.getElementById("caption");

                // Get the image and insert it inside the modal - use its "alt" text as a caption
                //var img = document.getElementById("myImg");
                document.querySelectorAll("img").forEach((img => {
                        img.onclick = function() {
                            modal.style.display = "block";
                            modalImg.src = this.src;
                            captionText.innerHTML = this.alt;
                        }
                    }))
                    // Get the <span> element that closes the modal
                var span = document.getElementsByClassName("close")[0];

                // When the user clicks on <span> (x), close the modal
                //span.onclick = function() {
                myModal.onclick = function() {
                    modal.style.display = "none";
                }


            }


            function markItem(id) {
                // Restaurem format de tots
                document.querySelectorAll("#TOC a").forEach(function(item) {
                        //item.style.fontWeight = "300";
                        item.classList.remove("navItemSelected");
                    })
                    //item.style.color = "#ff0000";

                // Afegim format
                let items = document.querySelectorAll("#TOC a[href='#" + id + "']");
                items.forEach(function(item) {
                    //item.style.fontWeight = "bolder";
                    item.classList.add("navItemSelected");
                })

            }

            var observer = new IntersectionObserver(function(entries) {
                // isIntersecting is true when element and viewport are overlapping
                // isIntersecting is false when element and viewport don't overlap
                if (entries[0].isIntersecting === true) {
                    let id = entries[0].target.id;
                    markItem(id);
                }

            }, {
                threshold: [0]
            });

            window.addEventListener("load", function() {
                document.querySelectorAll("h1, h2, h3").forEach(function(item) {
                    observer.observe(item);
                });

                document.querySelectorAll("#TOC a").forEach(function(item) {
                    item.addEventListener("click", function(item) {
                        markItem(item.id);
                    })
                })

                // Fem modals totes les imatges
                ModalizeImages();
            })

            document.querySelector("#TOC").addEventListener("click", function(event) {
                let toc = event.target
                if (toc.offsetWidth > 10) {
                    toc.classList.add("minimizedToc");
                }
            })

            document.querySelector("#TOC").addEventListener("mouseover", function(event) {
                let toc = event.target
                if (toc.classList.contains("minimizedToc"))
                    toc.classList.remove("minimizedToc");
            })


            //item.style.color = "#ff0000";
        </script>
    </div>
</body>

</html>